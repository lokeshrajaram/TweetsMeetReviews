-- adding serde jar for hive to understand how to serialize and deserialize tweets

add jar /home/ubuntu/lib/hive-serdes-1.0-SNAPSHOT.jar;

-- create tweets table for some analysis

CREATE EXTERNAL TABLE tweets (
  id BIGINT,
  created_at STRING,
  source STRING,
  favorited BOOLEAN,
  retweet_count INT,
  retweeted_status STRUCT<
    text:STRING,
    user:STRUCT<screen_name:STRING,name:STRING>>,
  entities STRUCT<
    urls:ARRAY<STRUCT<expanded_url:STRING>>,
    user_mentions:ARRAY<STRUCT<screen_name:STRING,name:STRING>>,
    hashtags:ARRAY<STRUCT<text:STRING>>>,
  text STRING,
  user STRUCT<
    screen_name:STRING,
    name:STRING,
    friends_count:INT,
    followers_count:INT,
    statuses_count:INT,
    verified:BOOLEAN,
    utc_offset:INT,
    time_zone:STRING>,
  in_reply_to_screen_name STRING
)
PARTITIONED BY (datehour INT)
ROW FORMAT SERDE 'com.cloudera.hive.serde.JSONSerDe'
LOCATION '/user/flume/tweets';

-- load data based on partition

LOAD DATA INPATH '$FILE_PATHÕ INTO TABLE default.tweets PARTITION (datehour='$PARTIOTION_KEYÕ);

(e.g) LOAD DATA INPATH '/user/flume/tweets/2014/06/21/00Õ INTO TABLE default.tweets PARTITION (datehour='2014062100Õ);



-- selective load

INSERT OVERWRITE DIRECTORY '/user/ubuntu/tweets/$PARTIOTION_KEY' select id, created_at, LOWER(text) from tweets where datehour='$PARTIOTION_KEY';



-- create table tweest_stats

CREATE EXTERNAL TABLE tweets_stats (
  id BIGINT,
  created_at STRING,
  text STRING,
  review_title STRING
)
PARTITIONED BY (datehour INT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
LOCATION '/user/ubuntu/tweets/processed';

LOAD DATA INPATH '/user/ubuntu/tweets/processed/$PARTIOTION_KEYÕ INTO TABLE default.tweets_stats PARTITION (datehour='$PARTIOTION_KEYÕ);

LOAD DATA INPATH '/user/ubuntu/tweets/processed/2014062908Õ INTO TABLE default.tweets_stats PARTITION (datehour='2014062908');
